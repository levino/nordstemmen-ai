# Nordstemmen MCP Server

MCP (Model Context Protocol) Server f√ºr semantische Suche in Nordstemmen-Dokumenten via Qdrant.

Deployed auf Cloudflare Pages unter: `nordstemmen-mcp.levinkeller.de`

## Features

- üîç Semantische Suche in Gemeinderatsdokumenten
- ‚ö° Cloudflare Pages (global edge network)
- ü§ñ HuggingFace Inference API f√ºr Embeddings
- üì° MCP-Standard kompatibel (JSON-RPC 2.0)

## Deployment via Cloudflare Pages

### 1. GitHub Repository erstellen

```bash
cd /workspaces/nordstemmen-ai/mcp-server
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/DEIN_USERNAME/nordstemmen-mcp-server.git
git push -u origin main
```

### 2. Cloudflare Pages Projekt erstellen

1. Cloudflare Dashboard ‚Üí Pages ‚Üí Create a project
2. Connect to Git ‚Üí Dein GitHub Repo ausw√§hlen
3. Build Settings:
   - **Framework preset**: None
   - **Build command**: (leer lassen)
   - **Build output directory**: (leer lassen)
4. Environment Variables setzen:
   - `QDRANT_URL`: `https://qdrant.levinkeller.de:443`
   - `QDRANT_COLLECTION`: `nordstemmen`
   - `QDRANT_API_KEY`: Dein Qdrant API Key
   - `HUGGINGFACE_API_KEY`: (Optional) Dein HuggingFace API Key
5. Save and Deploy

### 3. Custom Domain hinzuf√ºgen

1. Pages Projekt ‚Üí Custom domains
2. Add custom domain: `nordstemmen-mcp.levinkeller.de`
3. DNS Records werden automatisch erstellt

## Lokale Entwicklung

```bash
npm install
npm run dev
```

Server l√§uft auf `http://localhost:8788`

### Environment Variables f√ºr lokale Entwicklung

Erstelle `.dev.vars`:

```
QDRANT_URL=https://qdrant.levinkeller.de:443
QDRANT_COLLECTION=nordstemmen
QDRANT_API_KEY=dein_api_key
HUGGINGFACE_API_KEY=dein_hf_key  # Optional
```

## API Endpoints

### GET /

Health check / Info endpoint

```bash
curl https://nordstemmen-mcp.levinkeller.de/
```

### POST /mcp

MCP JSON-RPC Endpoint

**Initialize:**
```bash
curl -X POST https://nordstemmen-mcp.levinkeller.de/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "initialize",
    "params": {}
  }'
```

**List Tools:**
```bash
curl -X POST https://nordstemmen-mcp.levinkeller.de/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 2,
    "method": "tools/list",
    "params": {}
  }'
```

**Search Documents:**
```bash
curl -X POST https://nordstemmen-mcp.levinkeller.de/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 3,
    "method": "tools/call",
    "params": {
      "name": "search_documents",
      "arguments": {
        "query": "B√ºrgermeisterwahl",
        "limit": 5
      }
    }
  }'
```

## MCP Tool

Der Server stellt ein Tool bereit:

### `search_documents`

Durchsucht die Nordstemmen-Dokumentendatenbank.

**Parameter:**
- `query` (string, required): Suchbegriff oder Suchanfrage
- `limit` (number, optional): Anzahl der Ergebnisse (Standard: 5, Max: 10)

**R√ºckgabe:**
Formatierte Suchergebnisse mit:
- Dateiname und Seitenzahl
- Relevanz-Score
- Textausschnitt
- URL zum Originaldokument

## Verwendung mit Claude

### Claude Desktop

In `~/.config/claude-desktop/config.json`:

```json
{
  "mcpServers": {
    "nordstemmen": {
      "url": "https://nordstemmen-mcp.levinkeller.de/mcp"
    }
  }
}
```

### Andere MCP Clients

Der Server implementiert den MCP Standard (2024-11-05) und kann mit jedem kompatiblen Client verwendet werden.

## Projektstruktur

```
mcp-server/
‚îú‚îÄ‚îÄ _worker.ts           # Cloudflare Pages Worker (Advanced Mode)
‚îú‚îÄ‚îÄ package.json         # Dependencies
‚îú‚îÄ‚îÄ tsconfig.json        # TypeScript Config
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .dev.vars           # Lokale Environment Variables (nicht committen!)
‚îî‚îÄ‚îÄ README.md
```

## Technologie

- **Runtime**: Cloudflare Pages (Workers)
- **Vector DB**: Qdrant
- **Embeddings**: HuggingFace Inference API (`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`, 384 Dimensionen)
- **Protocol**: MCP (Model Context Protocol)
- **Transport**: JSON-RPC 2.0 over HTTP

## Hinweise

- Der Server nutzt HuggingFace Inference API f√ºr Embeddings (kostenlos, rate-limited)
- Optional: HuggingFace API Key f√ºr bessere Rate Limits
- Qdrant Collection nutzt 384-dimensionale Vektoren von `paraphrase-multilingual-MiniLM-L12-v2`
- Das gleiche Modell wie in der Streamlit-App f√ºr konsistente Ergebnisse

## Environment Variables

In Cloudflare Pages Settings konfiguriert:
- `QDRANT_URL`: Qdrant Server URL
- `QDRANT_COLLECTION`: Collection Name
- `QDRANT_API_KEY`: Qdrant API Key (erforderlich)
- `HUGGINGFACE_API_KEY`: HuggingFace API Key (optional)
