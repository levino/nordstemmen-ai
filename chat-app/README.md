# Nordstemmen Chat App

Eine Streamlit-basierte Chat-Anwendung zum Abfragen der Nordstemmen-Dokumente Ã¼ber Qdrant und Anthropic Claude.

## Features

- ğŸ’¬ Chat-Interface mit Verlauf
- ğŸ” Semantische Suche in Qdrant
- ğŸ¤– RAG (Retrieval-Augmented Generation) mit Claude
- ğŸ“š Quellenangaben fÃ¼r jede Antwort
- âš™ï¸ Konfigurierbare Suchparameter

## Installation

```bash
# Virtual Environment erstellen
python3 -m venv venv
source venv/bin/activate

# Dependencies installieren
pip install -r requirements.txt
```

## Verwendung

```bash
# App starten
streamlit run app.py
```

Die App Ã¶ffnet sich automatisch im Browser unter http://localhost:8501

## Konfiguration

In der Sidebar kannst du folgende Parameter einstellen:

### Qdrant
- **URL**: Die URL deines Qdrant-Servers (Standard: https://qdrant.levinkeller.de:443)
- **API Key**: Dein Qdrant API Key
- **Collection**: Name der Collection (Standard: nordstemmen)

### Anthropic
- **API Key**: Dein Anthropic API Key (https://console.anthropic.com/)

### Suche
- **Anzahl Suchergebnisse**: Wie viele Dokumente sollen fÃ¼r die Antwort verwendet werden (1-10)

## Features im Detail

### Semantische Suche
Die App verwendet das gleiche Embedding-Modell (`paraphrase-multilingual-MiniLM-L12-v2`) wie die Embedding-Generierung, um konsistente Suchergebnisse zu garantieren.

### RAG mit Claude
Die gefundenen Dokumente werden als Kontext an Claude Sonnet 3.5 gesendet, der darauf basierend eine prÃ¤zise Antwort formuliert.

### Quellenangaben
Zu jeder Antwort werden die verwendeten Quellen angezeigt:
- Dateiname
- Seitenzahl
- Relevanz-Score
- Textausschnitt

## Technologie-Stack

- **Frontend**: Streamlit
- **Vector Database**: Qdrant
- **LLM**: Claude 3.5 Sonnet (Anthropic)
- **Embeddings**: sentence-transformers
- **Model**: paraphrase-multilingual-MiniLM-L12-v2 (384 Dimensionen)
